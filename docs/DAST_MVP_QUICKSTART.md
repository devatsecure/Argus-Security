# DAST Phase 1 MVP - Quick Start Guide

## ğŸ¯ Overview

Phase 1 MVP delivers **enhanced DAST integration** with multi-agent parallel execution:

- **Nuclei Agent**: 4000+ templates, intelligent tech stack detection
- **ZAP Agent**: Spider + active scan, API testing
- **Parallel Execution**: Run both agents simultaneously (5-10 min total)
- **SAST-DAST Correlation**: Confirm exploitability, reduce false positives
- **100% Open Source**: No licensing costs

## âš¡ Quick Start (5 Minutes)

### 1. Install Dependencies

```bash
# Install Python dependencies
pip install -r requirements.txt

# Install Nuclei
brew install nuclei  # macOS
# OR
go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest

# Install ZAP (Docker)
docker pull ghcr.io/zaproxy/zaproxy:stable
```

### 2. Run Your First Scan

```bash
# Simple scan with defaults
python scripts/dast_orchestrator.py https://example.com

# API scan with OpenAPI spec
python scripts/dast_orchestrator.py \
    https://api.example.com \
    --openapi openapi.yaml \
    --output ./dast-results

# Fast scan (Nuclei only, 2-3 min)
python scripts/dast_orchestrator.py \
    https://example.com \
    --agents nuclei \
    --profile fast

# Comprehensive scan (Nuclei + ZAP, 15-30 min)
python scripts/dast_orchestrator.py \
    https://app.example.com \
    --agents nuclei,zap \
    --profile comprehensive \
    --project-path ./my-project
```

### 3. View Results

```bash
# Results saved to ./dast-results/
ls -la dast-results/

# Main report
cat dast-results/dast-results.json

# Agent-specific reports
cat dast-results/nuclei-results.json
cat dast-results/zap-results.json
```

## ğŸ¤– Multi-Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DAST Orchestrator                    â”‚
â”‚      (Parallel Execution Coordinator)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  Nuclei  â”‚            â”‚   ZAP    â”‚
    â”‚  Agent   â”‚            â”‚  Agent   â”‚
    â”‚  2-5 min â”‚            â”‚  5-10min â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Aggregator     â”‚
         â”‚  Deduplication   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Correlator     â”‚
         â”‚  SAST â†” DAST     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Reporter       â”‚
         â”‚  SARIF + JSON    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

### Using YAML Config

```yaml
# config/dast-config.yml
orchestrator:
  max_duration: 900
  parallel_agents: true
  enable_nuclei: true
  enable_zap: true

nuclei:
  enabled: true
  severity: [critical, high, medium]
  rate_limit: 150
  concurrency: 25

zap:
  enabled: true
  profile: balanced
  spider:
    max_depth: 3
    max_duration: 300
  active_scan:
    enabled: true
    max_duration: 600
```

### Using Python API

```python
from dast_orchestrator import DASTOrchestrator, OrchestratorConfig
from agents.nuclei_agent import NucleiConfig
from agents.zap_agent import ZAPConfig, ScanProfile

# Create configuration
config = OrchestratorConfig(
    parallel_agents=True,
    enable_nuclei=True,
    enable_zap=True,
    nuclei_config=NucleiConfig(
        severity=["critical", "high", "medium"],
        rate_limit=150,
    ),
    zap_config=ZAPConfig(
        profile=ScanProfile.BALANCED,
    ),
)

# Create orchestrator
orchestrator = DASTOrchestrator(config=config)

# Run scan
result = orchestrator.scan(
    target_url="https://example.com",
    openapi_spec="openapi.yaml",
    output_dir="./dast-results",
)

print(f"Total findings: {result.total_findings}")
```

## ğŸ¯ Scan Profiles

### Fast (2-3 minutes)
- **Nuclei only**
- Critical + High severity
- No active scanning

```bash
python scripts/dast_orchestrator.py \
    https://example.com \
    --agents nuclei \
    --profile fast
```

### Balanced (5-10 minutes) â­ **Recommended**
- **Nuclei + ZAP**
- Limited active scan
- Good coverage/speed trade-off

```bash
python scripts/dast_orchestrator.py \
    https://example.com \
    --agents nuclei,zap \
    --profile balanced
```

### Comprehensive (15-30 minutes)
- **Nuclei + ZAP**
- Full active scan
- AJAX spider
- Maximum coverage

```bash
python scripts/dast_orchestrator.py \
    https://example.com \
    --agents nuclei,zap \
    --profile comprehensive
```

## ğŸ”— SAST-DAST Correlation

Correlate static analysis (SAST) with dynamic testing (DAST) to confirm exploitability:

```bash
# Run SAST scan first (Semgrep, Trivy, etc.)
python scripts/hybrid_analyzer.py . --output-dir ./sast-results

# Run DAST scan
python scripts/dast_orchestrator.py \
    https://example.com \
    --output ./dast-results

# Correlate findings
python scripts/sast_dast_correlation_v2.py \
    --sast-file ./sast-results/results.json \
    --dast-file ./dast-results/dast-results.json \
    --output ./correlation-results.json

# View correlated findings
cat correlation-results.json | jq '.correlated_findings'
```

**Benefits:**
- âœ… Confirm SAST findings are exploitable
- âœ… Upgrade severity for correlated findings
- âœ… Reduce false positives by 30-40%
- âœ… Build exploit chains

## ğŸ” Authenticated Scanning

### Bearer Token

```bash
python scripts/dast_orchestrator.py \
    https://api.example.com \
    --agents nuclei,zap \
    --header "Authorization: Bearer eyJhbGciOiJIUzI1NiIs..."
```

### API Key

```python
config = OrchestratorConfig(
    nuclei_config=NucleiConfig(
        headers={
            "X-API-Key": "your-api-key",
            "Authorization": "Bearer token123",
        },
    ),
)
```

## ğŸ“Š Output Formats

### JSON (Programmatic)

```json
{
  "timestamp": "2026-01-27T10:30:00Z",
  "target_url": "https://example.com",
  "total_findings": 42,
  "severity_counts": {
    "critical": 2,
    "high": 8,
    "medium": 22,
    "low": 10
  },
  "aggregated_findings": [...]
}
```

### SARIF (GitHub Code Scanning)

```bash
# Convert to SARIF
python scripts/convert_to_sarif.py \
    --input dast-results/dast-results.json \
    --output dast-results.sarif

# Upload to GitHub
gh api /repos/{owner}/{repo}/code-scanning/sarifs \
    -F sarif=@dast-results.sarif \
    -F commit_sha=$GITHUB_SHA
```

## ğŸš€ GitHub Actions Integration

```yaml
name: DAST Scan

on:
  pull_request:
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight

jobs:
  dast-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Nuclei
        run: |
          go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
      
      - name: Run DAST Scan
        run: |
          python scripts/dast_orchestrator.py \
            https://staging.example.com \
            --agents nuclei,zap \
            --profile balanced \
            --output ./dast-results
      
      - name: Upload Results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: dast-results/dast-results.sarif
      
      - name: Fail if Critical/High
        run: |
          CRITICAL=$(jq '.severity_counts.critical' dast-results/dast-results.json)
          HIGH=$(jq '.severity_counts.high' dast-results/dast-results.json)
          if [ $CRITICAL -gt 0 ] || [ $HIGH -gt 5 ]; then
            echo "âŒ Found $CRITICAL critical, $HIGH high severity issues"
            exit 1
          fi
```

## ğŸ’° Cost & Performance

### Phase 1 MVP Scan:
- **Nuclei**: 2-3 minutes, **$0** (open source)
- **ZAP**: 5-8 minutes, **$0** (open source)
- **Correlation**: 10-30 seconds, **$0**
- **Total**: 5-10 minutes, **$0**

### vs Commercial Tools:
- Burp Suite Pro: $449/year per user
- Veracode DAST: $1,500-3,000/app/year
- Checkmarx DAST: Custom pricing ($$$$$)

**Argus Phase 1 MVP: FREE** âœ¨

## ğŸ“ˆ Success Metrics

Phase 1 MVP targets:
- âœ… **50%+ coverage improvement** over Nuclei alone
- âœ… **30%+ false positive reduction** via correlation
- âœ… **5-10 minute** scan time (balanced mode)
- âœ… **90%+ OWASP Top 10** detection rate
- âœ… **$0 cost** (all open source)

## ğŸ”® Phase 2 (Future)

- Burp Suite integration
- Environment-aware scanning
- Continuous DAST monitoring
- ML-based attack generation
- Vulnerability chaining

## ğŸ“š Examples

See `examples/dast_mvp_example.py` for:
1. Simple scan
2. API scan with OpenAPI
3. Authenticated scan
4. Fast scan
5. Comprehensive scan
6. SAST-DAST correlation

## ğŸ†˜ Troubleshooting

### Nuclei not found
```bash
# Install Nuclei
go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest

# Or use Homebrew
brew install nuclei
```

### ZAP Docker image not found
```bash
docker pull ghcr.io/zaproxy/zaproxy:stable
```

### Slow scans
```bash
# Use fast profile
python scripts/dast_orchestrator.py \
    https://example.com \
    --profile fast \
    --agents nuclei

# Or increase concurrency
python scripts/dast_orchestrator.py \
    https://example.com \
    --agents nuclei \
    --concurrency 50
```

## ğŸ“ Support

- **Documentation**: `docs/MULTI_AGENT_DAST_ARCHITECTURE.md`
- **Examples**: `examples/dast_mvp_example.py`
- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions

---

**Built with â¤ï¸ by the Argus Security team**
